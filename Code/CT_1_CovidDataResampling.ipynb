{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d076e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5f4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING THIS DATASET IS & MILLION ROWS LONG AND IT WILL TAKE A WHILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71693fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv\n",
    "columns = ['res_state','res_county','age_group','sex','race','ethnicity','hosp_yn']\n",
    "\n",
    "target = ['hosp_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b18c340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res_state</th>\n",
       "      <th>res_county</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>hosp_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CT</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  res_state res_county       age_group     sex   race        ethnicity hosp_yn\n",
       "0        CT  NEW HAVEN  18 to 49 years    Male  Black  Hispanic/Latino     Yes\n",
       "1        CT  NEW HAVEN  18 to 49 years    Male  Black  Hispanic/Latino      No\n",
       "2        CT  NEW HAVEN  18 to 49 years  Female  Black  Hispanic/Latino      No\n",
       "3        CT  NEW HAVEN  18 to 49 years  Female  Black  Hispanic/Latino      No\n",
       "4        CT  NEW HAVEN  18 to 49 years  Female  Black  Hispanic/Latino      No"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('connecticut_covid.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8307c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res_state     26365\n",
       "res_county    26365\n",
       "age_group     26365\n",
       "sex           26365\n",
       "race          26365\n",
       "ethnicity     26365\n",
       "hosp_yn       26365\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f5ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26365 entries, 0 to 26364\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   res_state   26365 non-null  object\n",
      " 1   res_county  26365 non-null  object\n",
      " 2   age_group   26365 non-null  object\n",
      " 3   sex         26365 non-null  object\n",
      " 4   race        26365 non-null  object\n",
      " 5   ethnicity   26365 non-null  object\n",
      " 6   hosp_yn     26365 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4ef8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into trainign and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add266e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features, and drop the laon status and get dummies\n",
    "X = df.drop('hosp_yn', axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create our target\n",
    "y = df['hosp_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7f7c5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>res_state_CT</th>\n",
       "      <th>res_county_FAIRFIELD</th>\n",
       "      <th>res_county_HARTFORD</th>\n",
       "      <th>res_county_LITCHFIELD</th>\n",
       "      <th>res_county_MIDDLESEX</th>\n",
       "      <th>res_county_NEW HAVEN</th>\n",
       "      <th>res_county_NEW LONDON</th>\n",
       "      <th>res_county_TOLLAND</th>\n",
       "      <th>res_county_WINDHAM</th>\n",
       "      <th>age_group_0 - 17 years</th>\n",
       "      <th>...</th>\n",
       "      <th>age_group_65+ years</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>race_American Indian/Alaska Native</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Multiple/Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>ethnicity_Hispanic/Latino</th>\n",
       "      <th>ethnicity_Non-Hispanic/Latino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26365.0</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "      <td>26365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.229509</td>\n",
       "      <td>0.290650</td>\n",
       "      <td>0.041039</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.343258</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.040622</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.553158</td>\n",
       "      <td>0.446842</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.209520</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.781908</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.884696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420525</td>\n",
       "      <td>0.454071</td>\n",
       "      <td>0.198385</td>\n",
       "      <td>0.148280</td>\n",
       "      <td>0.474806</td>\n",
       "      <td>0.157834</td>\n",
       "      <td>0.197417</td>\n",
       "      <td>0.082573</td>\n",
       "      <td>0.177041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487567</td>\n",
       "      <td>0.497176</td>\n",
       "      <td>0.497176</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.086336</td>\n",
       "      <td>0.406974</td>\n",
       "      <td>0.031388</td>\n",
       "      <td>0.412958</td>\n",
       "      <td>0.319395</td>\n",
       "      <td>0.319395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       res_state_CT  res_county_FAIRFIELD  res_county_HARTFORD  \\\n",
       "count       26365.0          26365.000000         26365.000000   \n",
       "mean            1.0              0.229509             0.290650   \n",
       "std             0.0              0.420525             0.454071   \n",
       "min             1.0              0.000000             0.000000   \n",
       "25%             1.0              0.000000             0.000000   \n",
       "50%             1.0              0.000000             0.000000   \n",
       "75%             1.0              0.000000             1.000000   \n",
       "max             1.0              1.000000             1.000000   \n",
       "\n",
       "       res_county_LITCHFIELD  res_county_MIDDLESEX  res_county_NEW HAVEN  \\\n",
       "count           26365.000000          26365.000000          26365.000000   \n",
       "mean                0.041039              0.022492              0.343258   \n",
       "std                 0.198385              0.148280              0.474806   \n",
       "min                 0.000000              0.000000              0.000000   \n",
       "25%                 0.000000              0.000000              0.000000   \n",
       "50%                 0.000000              0.000000              0.000000   \n",
       "75%                 0.000000              0.000000              1.000000   \n",
       "max                 1.000000              1.000000              1.000000   \n",
       "\n",
       "       res_county_NEW LONDON  res_county_TOLLAND  res_county_WINDHAM  \\\n",
       "count           26365.000000        26365.000000        26365.000000   \n",
       "mean                0.025564            0.040622            0.006865   \n",
       "std                 0.157834            0.197417            0.082573   \n",
       "min                 0.000000            0.000000            0.000000   \n",
       "25%                 0.000000            0.000000            0.000000   \n",
       "50%                 0.000000            0.000000            0.000000   \n",
       "75%                 0.000000            0.000000            0.000000   \n",
       "max                 1.000000            1.000000            1.000000   \n",
       "\n",
       "       age_group_0 - 17 years  ...  age_group_65+ years    sex_Female  \\\n",
       "count            26365.000000  ...         26365.000000  26365.000000   \n",
       "mean                 0.032391  ...             0.389152      0.553158   \n",
       "std                  0.177041  ...             0.487567      0.497176   \n",
       "min                  0.000000  ...             0.000000      0.000000   \n",
       "25%                  0.000000  ...             0.000000      0.000000   \n",
       "50%                  0.000000  ...             0.000000      1.000000   \n",
       "75%                  0.000000  ...             1.000000      1.000000   \n",
       "max                  1.000000  ...             1.000000      1.000000   \n",
       "\n",
       "           sex_Male  race_American Indian/Alaska Native    race_Asian  \\\n",
       "count  26365.000000                        26365.000000  26365.000000   \n",
       "mean       0.446842                            0.000076      0.007510   \n",
       "std        0.497176                            0.008709      0.086336   \n",
       "min        0.000000                            0.000000      0.000000   \n",
       "25%        0.000000                            0.000000      0.000000   \n",
       "50%        0.000000                            0.000000      0.000000   \n",
       "75%        1.000000                            0.000000      0.000000   \n",
       "max        1.000000                            1.000000      1.000000   \n",
       "\n",
       "         race_Black  race_Multiple/Other    race_White  \\\n",
       "count  26365.000000         26365.000000  26365.000000   \n",
       "mean       0.209520             0.000986      0.781908   \n",
       "std        0.406974             0.031388      0.412958   \n",
       "min        0.000000             0.000000      0.000000   \n",
       "25%        0.000000             0.000000      1.000000   \n",
       "50%        0.000000             0.000000      1.000000   \n",
       "75%        0.000000             0.000000      1.000000   \n",
       "max        1.000000             1.000000      1.000000   \n",
       "\n",
       "       ethnicity_Hispanic/Latino  ethnicity_Non-Hispanic/Latino  \n",
       "count               26365.000000                   26365.000000  \n",
       "mean                    0.115304                       0.884696  \n",
       "std                     0.319395                       0.319395  \n",
       "min                     0.000000                       0.000000  \n",
       "25%                     0.000000                       1.000000  \n",
       "50%                     0.000000                       1.000000  \n",
       "75%                     0.000000                       1.000000  \n",
       "max                     1.000000                       1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9d53f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     17919\n",
       "Yes     8446\n",
       "Name: hosp_yn, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40044c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'No': 13454, 'Yes': 6319})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32133cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "#naive random oversampling, resample the trainging data with the RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd6b631b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'No': 13454, 'Yes': 13454})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37c845d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afann\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7d71c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2885, 1580],\n",
       "       [ 516, 1611]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75213ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017707068138492"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45cd3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.85      0.65      0.76      0.73      0.70      0.48      4465\n",
      "        Yes       0.50      0.76      0.65      0.61      0.70      0.49      2127\n",
      "\n",
      "avg / total       0.74      0.68      0.72      0.69      0.70      0.49      6592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31cb974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60555662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bead534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afann\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6689b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701871580189859"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b5e2008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2888, 1577],\n",
       "       [ 517, 1610]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d910fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         No       0.85      0.65      0.76      0.73      0.70      0.48      4465\n",
      "        Yes       0.51      0.76      0.65      0.61      0.70      0.49      2127\n",
      "\n",
      "avg / total       0.74      0.68      0.72      0.69      0.70      0.49      6592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3f721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlev",
   "language": "python",
   "name": "mlev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
